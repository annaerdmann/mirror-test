{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb9ccae1",
   "metadata": {},
   "source": [
    "# Ocean colour geospatial foundation model (GFM) demo notebook\n",
    "\n",
    "The following notebook demonstrates fine-tuning the ocean colour geospatial foundation model for primary production quantification. The notebook makes use of [TerraTorch](https://github.com/IBM/terratorch) for fine-tuning and prediction.\n",
    "\n",
    "The primary production data used in fine-tuning were collected from various sources [Mattei, Francesco; Scardi, Michele (2021)](https://doi.pangaea.de/10.1594/PANGAEA.932417), simons_cmap_2023_10019979, Marra2021,Buitenhuis2013,Goericke2021} and include ship-bourne observations and buoy data. The accompanying Sentinel-3 Ocean Land Colour Instrument (OLCI) and Sea and Land Surface Temperature Radiometer (SLSTR) images were created from a 6 day median of all cloud free measurements. Full details on the creation of this dataset can be found [here]().\n",
    "\n",
    "It's best to run this notebook on a machine with one or more GPUs. If this is not possible, you can reduce the amount of training data to shorten the training time, at a cost of reduced performance. You can also try reducing the batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c44b1b8",
   "metadata": {},
   "source": [
    "## 0.1 Setup for running on Google colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8444210f",
   "metadata": {},
   "source": [
    "You may want to take this opportunity to double check you're using GPUs on Google Colab before proceeding any further. We have tested this notebook using T4 GPU on the free colab account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605a577b",
   "metadata": {},
   "source": [
    "### 0.1.1 Check python version\n",
    "\n",
    "It's recommended that you run this notebook using python 3.10. Let's check the python version by executing the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9f8742",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b5118e",
   "metadata": {},
   "source": [
    "### 0.1.2 Setup environment \n",
    "\n",
    "To install the necessary packages on Colab, execute the cell below. This will take a few minutes. Once the installation process is done, a window will pop up to ask you to restart the session. This is normal and you should proceed to restart using the interface in the pop up window. Once the session has restarted, it's important that you ignore the cell below, and go straight to section 0.1.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd24c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# if running on colab\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Clone the ibm-granite GitHub repo\n",
    "    !git clone https://github.com/ibm-granite/geospatial.git\n",
    "    # Install the package\n",
    "    !pip install -e ./geospatial/granite-geospatial-ocean[colab]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fae39ac",
   "metadata": {},
   "source": [
    "### 0.1.3 Set up working directory\n",
    "\n",
    "This is the first thing you should run after restarting your Colab session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1ed56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell if running on Colab.\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Change to the notebooks directory\n",
    "    %cd geospatial/granite-geospatial-ocean/notebooks\n",
    "    %pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795e9a14",
   "metadata": {},
   "source": [
    "Now your environment is set up for Google Colab. Please proceed to section 0.3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca62847f",
   "metadata": {},
   "source": [
    "## 0.2 set-up for running on your local machine\n",
    "\n",
    "Before running through this notebook it's best to create a virtual environment and install the necessary packages there before running this notebook. The instructions can be found in README.md.\n",
    "\n",
    "Once that's done, come back to this notebook and make sure it's using the newly made virtual environment.\n",
    "\n",
    "Please proceed to section 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3e6fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import rioxarray\n",
    "import tarfile\n",
    "import zipfile\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "from pathlib import Path\n",
    "\n",
    "from granite_geo_ocean_colour.helper import (\n",
    "    get_rgb,\n",
    "    plot_inference_data,\n",
    "    plot_training_data,\n",
    "    crop_image,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8cf297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some basic set-up\n",
    "%matplotlib inline\n",
    "\n",
    "project_root = Path(\"../\")\n",
    "hf_repo_name = \"ibm-granite/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab35fc8",
   "metadata": {},
   "source": [
    "## 1. Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8432cc",
   "metadata": {},
   "source": [
    "### 1.1 Data prep\n",
    "\n",
    "Let's place this in the `granite-geospatial-ocean/data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd7fa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data set\n",
    "dataset_name = \"granite-geospatial-ocean-processed-sentinel-3-primary-production.tar.gz\"\n",
    "data_url = f\"https://zenodo.org/records/17093560/files/{dataset_name}\"\n",
    "download_cmd = f\"wget {data_url} -O {project_root}/{dataset_name}\"\n",
    "os.system(download_cmd)\n",
    "\n",
    "# unzip\n",
    "with tarfile.open(f\"{project_root}/{dataset_name}\", \"r:gz\") as tar:\n",
    "    tar.extractall(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c274cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify where the training and inference data are stored\n",
    "data_path = project_root / \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfe068b",
   "metadata": {},
   "source": [
    "#### Plot some samples.\n",
    "\n",
    "Here we randomly plot some of the samnple in the fine-tuning dataset. As Sentinel-3 OLCI data does not have seperate red green blue bands we have plotted a log scales natural colour broad band, log scaled. This code was taken from [EUMETlab](https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/sensors/learn-olci) repository wihich is a great resource for learning more about the data.\n",
    "\n",
    "Note that the label location is shown in purple in the centre of each image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0ac147",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_data_path = glob.glob(f\"{data_path}/*/*_img.tif\")\n",
    "selected_images = random.sample(ft_data_path, 4)\n",
    "\n",
    "plot_training_data(selected_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132aa808",
   "metadata": {},
   "source": [
    "### 1.2 Model prep - checkpoints\n",
    "\n",
    "Download the pre-trained model weights from HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283d175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint-specific\n",
    "checkpoint_folder = project_root / \"data\" / \"checkpoints\"\n",
    "os.makedirs(checkpoint_folder, exist_ok=True)\n",
    "\n",
    "hf_repo_name = \"ibm-granite/granite-geospatial-ocean\"\n",
    "\n",
    "inference_checkpoint = Path(\n",
    "    hf_hub_download(\n",
    "        repo_id=hf_repo_name,\n",
    "        filename=\"checkpoint.pt\",\n",
    "        local_dir=checkpoint_folder,\n",
    "    )\n",
    ")\n",
    "\n",
    "config_name = \"config.yaml\"\n",
    "config_folder = project_root / \"configs\"\n",
    "\n",
    "# download model config\n",
    "model_config = Path(\n",
    "    hf_hub_download(\n",
    "        repo_id=hf_repo_name,\n",
    "        filename=config_name,\n",
    "        local_dir=config_folder,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b197118",
   "metadata": {},
   "source": [
    "### 1.3 Model prep - configs\n",
    "\n",
    "As this model uses different bands to the prithvi model included in terratorch, we allow for the weights for these additional bands to be read in by terratorch by defining a custom module in [./custom_modules/prithvi_vi_S3.py](../custom_modules/prithvi_vit_S3.py).\n",
    "\n",
    "We make sure to point to this as a backbone in our config file.\n",
    "\n",
    "We have also set the maximum epochs to 30 for this demonstration, but you may want to run the model for more epochs (e.g. 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7961e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = config_folder / \"config-fine-tuning.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93418c28",
   "metadata": {},
   "source": [
    "### 1.4 Carry out fine-tuning\n",
    "\n",
    "Execute the below cell to print out a command. Check the command and the config location to make sure that the config file exists in the expected folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd967ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuning_command = f\"terratorch fit --config ./{config_file}\"\n",
    "print(fine_tuning_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d41297",
   "metadata": {},
   "source": [
    "If everything looks ok, we'll execute the below cell to fine-tune the model. This command will place the fine-tuning output in `model_run/version_0` if it is the first time it has been run and subsequent versions for additional runs. The fine-tuning output includes the model checkpoints used in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16f3fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(fine_tuning_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfd2451",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Checking the results - inference prep\n",
    "\n",
    "Let's gather and specify the relevant files for carrying out inference in a new folder. Look for your .ckpt file produced during the fine-tuning process and list it in the cell in section 2.1. We are perfoming inference for a region off the coast of Spain and Portugal between 7th and 13th July 2020.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2553242e",
   "metadata": {},
   "source": [
    "### 2.1 Inference checkpoint specification\n",
    "Identify the model_run directory containing the correct checkpoint file you wish to use. This will be in `model_runs/version_0` the first time fine-tuning is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12948749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the checkpoint produced from the fine-tuning process, and overwrite below\n",
    "inference_checkpoint_loc = project_root / \"data\" / \"model_runs\" / \"version_0\"\n",
    "\n",
    "inference_checkpoint = glob.glob(f\"{inference_checkpoint_loc}/checkpoints/*.ckpt\")\n",
    "inference_checkpoint = min(inference_checkpoint, key=len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2e7cde",
   "metadata": {},
   "source": [
    "### 2.2 Preparing paths for inference results\n",
    "Create a new directory for the inference results to be placed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7e3ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_output = project_root / \"data\" / \"inference_results\"\n",
    "inference_input =  project_root / \"data\" / \"inference\"\n",
    "\n",
    "os.makedirs(inference_output, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee762ab5",
   "metadata": {},
   "source": [
    "The region we are running inference on is quite large, so may take a long time to run. If you want inference to run faster run this cell below as it will crop the image to a smaller area. Otherwise skip the cell below and go directly to running inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69eafc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = [-9.8,42.5,-8.7,43.3]\n",
    "inference_image = inference_input / '2020-07-07_00_00_00+2020-07-13_00_00_00_img.tif'\n",
    "crop_image(inference_image, bbox, inference_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd556ed5",
   "metadata": {},
   "source": [
    "### 2.3 Run \n",
    "Let's carry out inference on the test images. Execute the cell below to print out a command. Make sure the paths look correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ff795",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_command = f\"terratorch predict -c {config_file} --ckpt_path {inference_checkpoint} --predict_output_dir ./{inference_output} --data.init_args.predict_data_root ./{inference_input}\"\n",
    "print(inference_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be80c35",
   "metadata": {},
   "source": [
    "If everything looks good, execute the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f5b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(inference_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a297d7f",
   "metadata": {},
   "source": [
    "## 3. Checking and visualizing results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ae7d0b",
   "metadata": {},
   "source": [
    "We can then plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9761a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inference_data(\n",
    "    f\"{inference_input}/2020-07-07_00_00_00+2020-07-13_00_00_00_img.tif\",\n",
    "    f\"{inference_output}/2020-07-07_00_00_00+2020-07-13_00_00_00_img_pred.tif\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee43d5c",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d7723",
   "metadata": {},
   "source": [
    "Check out the other granite-geospatial models for [Above Ground Biomass](https://huggingface.co/ibm-granite/granite-geospatial-biomass), [Canopy Height](https://huggingface.co/ibm-granite/granite-geospatial-canopyheight), [Land Surface Temperature](https://huggingface.co/ibm-granite/granite-geospatial-land-surface-temperature) and [Weather and Climate Downscaling](https://huggingface.co/ibm-granite/granite-geospatial-wxc-downscaling)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s3dld",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
